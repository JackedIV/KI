{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Grundlagen künstlicher Intelligenz\n",
    "<br><br>\n",
    "Sommersemester 2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Machine Learning Algorithms & Clustering\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Freitag, 26.06.2020 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Machen Sie sich mit dem Datensatz Iris (iris.csv) vertraut.<br><br>\n",
    "*Take a look at the Iris record (iris.csv).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Wie viele verschiedene class labels gibt es und wie finden sie sich im Datensatz wieder?<br><br>\n",
    "*How many different class labels are there and how can they be found in the dataset?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Welche Features gibt es und welche Datenart haben sie?<br><br>\n",
    "*What features are there and what type of data do they have?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Schauen Sie sich die Plots an. Welche Klasse ist am einfachsten zu differenzieren?<br><br>\n",
    "*Look at the plots. Which class is easiest to differentiate?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lassen Sie sich lineare Regressions Modelle für gepaarte Features anzeigen. Wie schätzen Sie die Güte dieser Methode ein? Für welche zwei Features passt es am besten und wie würden Sie das semantisch interpretieren?<br><br>\n",
    "*View linear regression models for paired features. How do you rate the quality of this method? For which two features does it best fit and how would you interpret it semantically?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "iris_skl = load_iris() # load the iris dataset\n",
    "iris_sns = sns.load_dataset(\"iris\")\n",
    "\n",
    "# show the class distribution\n",
    "%matplotlib inline \n",
    "print(iris_sns.head())\n",
    "print(list(iris_skl.target_names))\n",
    "\n",
    "sns.countplot(x=\"species\", data = iris_sns, palette=\"husl\")\n",
    "\n",
    "sns.pairplot(iris_sns, hue=\"species\", palette=\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lassen Sie sich den Baum (ohne Tiefenbegrenzung) ausgeben. Was fällt Ihnen auf? An welchen Stellen sind weitere Knoten nicht sinnvoll und wie könnte man das beheben?<br><br>\n",
    "*Output the tree (without depth limit). What do you notice? At which points are further nodes not useful and how could this be corrected?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Schauen Sie sich folgenden Code Zeilen an. Gini Index und Entropy bewerten jeweils die Knoten und können beim Decision Tree angewendet werden. Was wäre hier unvorteilhafter? Vergleichen Sie beim Digit Datensatz.<br><br>\n",
    "*Look at the following code lines. Gini Index and Entropy both evaluate the nodes and can be applied to the decision tree. What would be more unfavorable? Compare them with the digit data set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini_score = 1 - sum([i**2 for i in values])\n",
    "# entropy_score = sum([-i*log(i,2) for i in values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Export as dot file\n",
    "export_graphviz(classifier, out_file='tree.dot',\n",
    "                feature_names=iris_skl.feature_names,\n",
    "                class_names=iris_skl.target_names, \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png'], shell=True)\n",
    "\n",
    "# Display in jupyter notebook\n",
    "display(Image(filename = 'tree.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3:</i> <br>\n",
    "</div>\n",
    "\n",
    "Schauen Sie sich den unten gegebenen Code an.<br><br>\n",
    "*Take a look at the code below.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import datasets, svm, tree, metrics\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "x_train, y_train = data[:n_samples // 2], digits.target[:n_samples // 2]\n",
    "x_test, y_test = data[n_samples // 2:], digits.target[n_samples // 2:]\n",
    "\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Train-Time\", \"Predict-Time\", \"Accuracy-Train\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "log_short = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for clf in classifiers:\n",
    "    t0 = time.process_time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    t1 = time.process_time()\n",
    "    training_time = t1-t0\n",
    "    \n",
    "    name = clf.__class__.__name__\n",
    "    name_short = clf.__class__.__name__[:3]\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    t0 = time.process_time()\n",
    "    predictions = clf.predict(x_test)\n",
    "    predictions_train = clf.predict(x_train)\n",
    "    t1 = time.process_time()\n",
    "    predict_time = t1-t0\n",
    "\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "    print(\"Accuracy on Training Set: {:.4%}\".format(acc_train))\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy on Test Set: {:.4%}\".format(acc))\n",
    "        \n",
    "    log_entry = pd.DataFrame([[name, acc*100, training_time, predict_time, acc_train*100]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    log_entry_short = pd.DataFrame([[name_short, acc*100, training_time, predict_time, acc_train*100]], columns=log_cols)\n",
    "    log_short = log_short.append(log_entry_short)\n",
    "    \n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
    "plt.show()\n",
    "sns.barplot(x='Accuracy-Train', y='Classifier', data=log, color=\"m\")\n",
    "plt.show()\n",
    "sns.barplot(x='Train-Time', y='Classifier', data=log, color=\"r\")\n",
    "plt.show()\n",
    "sns.barplot(x='Predict-Time', y='Classifier', data=log, color=\"g\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)\n",
    "\n",
    "\n",
    "fig, host = plt.subplots()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "par1 = host.twinx()\n",
    "par2 = host.twinx()\n",
    "\n",
    "par2.spines[\"right\"].set_position((\"axes\", 1.2))\n",
    "make_patch_spines_invisible(par2)\n",
    "par2.spines[\"right\"].set_visible(True)\n",
    "\n",
    "p1, = host.plot('Classifier', 'Accuracy', data=log_short, color=\"b\")\n",
    "p2, = par1.plot('Classifier', 'Train-Time', data=log_short, color=\"r\")\n",
    "p3, = par2.plot('Classifier', 'Predict-Time', data=log_short, color=\"g\")\n",
    "\n",
    "host.set_xlabel(\"Classifier\")\n",
    "host.set_ylabel(\"Accuracy\")\n",
    "par1.set_ylabel(\"Train-Time\")\n",
    "par2.set_ylabel(\"Predict-Time\")\n",
    "\n",
    "lines = [p1, p2, p3]\n",
    "host.legend(lines, [l.get_label() for l in lines], loc=\"upper center\", bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vergleichen Sie die einzelnen Classifier anhand der Plots, woran würden Sie die Qualität fest machen? Wie würden Sie die Laufzeit gewichten?<br><br>\n",
    "*Based on the plots, compare the classifiers to each other. How would you determine the quality of the classifier? How would you weight the runtime?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Schauen Sie sich die Plots an. Warum ist die Accuracy bei den Trainingsdaten besser als bei den Testdaten?<br><br>\n",
    "*Take a look at the plots. Why is accuracy better for the training data than for the test data?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. Schauen Sie sich die Parameter beim SVC an. Handelt es sich um einen hard margin oder soft margin und was halten Sie prinzipiell für besser?<br><br>\n",
    "*Look at the parameters of the SVC. Is it a hard margin or soft margin and what do you think is better in principal?*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Welchen Classifier würden Sie als am schlechtesten einschätzen? Woran könnte das liegen? Binden Sie eine mögliche Verbesserungsmethode ein.<br><br>\n",
    "*Which classifier would you consider to be the worst? What could be the reason? Suggest a possible improvement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Übliche Größen für Test Sets sind 10-20% der Daten. Ändern Sie den Code dahingehend und schauen Sie sich die Veränderungen. Woher kommen die Verbesserungen?<br><br>\n",
    "*Common sizes for test sets are 10-20% of the data. Change the code accordingly and look at the changes. Where do the improvements come from?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 4:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Für welche Art von Problemen wird Clustering verwendet im Vergleich zu anderen Machine Learning Verfahren? Nennen Sie ein Beispiel.<br><br>\n",
    "*What kind of problems would clustering be used for, in comparison to other Machine Learning models? Name an example.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Schauen Sie sich den untenstehenden Code und dessen Ausgabe an. Welches k ist optimal und wie sehen die Cluster aus?<br><br>\n",
    "*Look at the code below and its output. What is the optimum value for k and how does the cluster look like?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pandas\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Settings:\n",
    "min_clusters = 2\n",
    "max_clusters = 8\n",
    "colors = ['red', 'blue', 'lightgreen', 'darkgreen', 'purple', 'yellow', 'pink']\n",
    "\n",
    "# Load dataset and drop column 'target'.\n",
    "data = pandas.read_csv(\"data/ex9/wine_data_mod.csv\", sep=\",\")\n",
    "data = data.drop(\"target\", axis=1)\n",
    "\n",
    "# Extract the values and preprocess them.\n",
    "winearray = data.values\n",
    "winearray_norm = sklearn.preprocessing.scale(winearray)\n",
    "kmeans_sil_scores = []\n",
    "\n",
    "for num_clusters in range(min_clusters, max_clusters):\n",
    "    # Execute KMeans algorithm.\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=num_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(winearray_norm)\n",
    "    \n",
    "    # Compute silhouette score.\n",
    "    silhouette_avg = silhouette_score(winearray_norm, cluster_labels)\n",
    "    print(\"For n_clusters =\", num_clusters, \"The average silhouette_score is :\", silhouette_avg)\n",
    "    print(\"Nr of samples per Cluster: \", np.bincount(cluster_labels))    \n",
    "    kmeans_sil_scores.append([num_clusters, silhouette_avg])\n",
    "    \n",
    "    # Project the dataset into lower dimensional space\n",
    "    pca = PCA()\n",
    "    transformed = pd.DataFrame(pca.fit_transform(winearray_norm))\n",
    "    \n",
    "    # Plot the clustering results.\n",
    "    for c, color in zip(range(num_clusters), colors):\n",
    "        x = transformed[cluster_labels==c][0]\n",
    "        y = transformed[cluster_labels==c][1]\n",
    "        \n",
    "        plt.scatter(x, y, label='Cluster {}'.format(c + 1), color=color)\n",
    "    \n",
    "    # Show the resulting visualization.\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "table_index = []\n",
    "table_kmeans = []\n",
    "\n",
    "for num_clusters, silhouette_avg in kmeans_sil_scores:\n",
    "    table_index.append(num_clusters)\n",
    "    table_kmeans.append(silhouette_avg)\n",
    "\n",
    "# Print the results as a table.\n",
    "df = pandas.DataFrame({'Clusters':table_index, 'K-Means':table_kmeans})\n",
    "print(df[['Clusters', 'K-Means']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abgaberichtlinien\n",
    "* Jede Hausübung bringt maximal 10 Hausaufgabenpunkte. 10 Hausaufgabenpunkte entsprechen einem Klausurpunkt.\n",
    "* Im Laufe des Semesters kann es zusätzliche Bonuspunkte (= 1 Klausurpunkt) für Hausübungen geben, in Form von z.B. Challenges, weitere Informationen folgen bei den betreffenden Hausübungen.\n",
    "* Die Abgabe erfolgt in Zweier- oder Dreierteams. **Einzelabgaben werden nicht gewertet**. Die Teammitglieder müssen nicht in derselben Übungsgruppe sein. Bei Problemen bzw. Einzelfällen hinsichtlich dieser Richtlinie kontaktieren Sie einen Tutor.\n",
    "* In der Abgabe müssen alle Teammitglieder mit **Namen und Matrikelnummern gut sichtbar** genannt werden.\n",
    "* Es muss immer nur **ein Teammitglied der Gruppe abgeben**. Sollten aus Versehen mehrere Abgaben der selben Übung erfolgen, kommunizieren Sie dies **zeitnah** an einen Tutor, ansonsten wird die erste korrigierte Abgabe gewertet.\n",
    "* Die Abgabe soll als Jupyter-Notebook erfolgen (.ipynb). Abgaben in einem **anderen Format werden nicht gewertet**. Bei Problemen hinsichtlich dieser Richtlinie kontaktieren Sie einen Tutor.\n",
    "* Es ist nicht nötig, den Präsenzübungsteil in der Abgabe mit abzugeben. Es wird lediglich der Hausübungsteil gewertet.\n",
    "* Wenn Bilder mit abgegeben werden, ist es erlaubt, diese zusammen mit dem Notebook als zip-Ordner abzugeben. Diese sollten folgendermaßen eingefügt werden: ``![Beispiel1](Beispielbild1.PNG)`` (ohne Apostrophe in einer Markdown-Cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Submission guidelines*\n",
    "* *You can reach up to 10 homework points for every homework submission. 10 homework points correspond to one exam point.*\n",
    "* *In the course of the semester, there will be extra bonus points (where each bonus point equals to one exam point) for the homeworks. These will be given in the form of e.g. challenges inside the homeworks. More information will be given in the corresponding homeworks.*\n",
    "* *The submission has to be done by a team of two to three people. **Individual submissions will not be graded**. The team members do not have to attend the same exercise group. If there are any problems regarding this guideline, please reach out to a tutor.*\n",
    "* *Please state the **name and matriculation number of all team members** in every submission **clearly**.*\n",
    "* *Only **one team member should submit** the homework. If more than one version of the same homework is submitted by accident (submitted by more than one group member), please reach out to a tutor **as soon as possible**. Otherwise, the first submitted homework will be graded.*\n",
    "* *The submission must be in a Jupyter Notebook format (.ipynb). Submissions in **other formats will not be graded**. If there are any problems regarding this guideline, please reach out to a tutor.*\n",
    "* *It is not necessary to also submit the part of the exercise discussed by the tutor, please only submit the homework part.*\n",
    "* *If pictures need to be submitted, it is allowed to hand them in in a zip folder, together with the notebook. They should be added to the notebook like this: ``![example1](examplepicture1.PNG)`` (without apostrophs in a Markdown-Cell).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 1:</i>\n",
    "        ::: 10 Hausaufgabenpunkte :::</div>\n",
    "\n",
    "Gehen Sie jeden der folgenden Schritte durch und berichten Sie kurz über Ihr Vorgehen:<br><br>\n",
    "<i>Go through the following steps and make a short report on your approach: </i>\n",
    "\n",
    "1. Erstellen Sie einen kurzen dummy Datensatz (MeinDatensatz.csv) mit mindestens 20 Instanzen zu einem Thema Ihrer Wahl. Dieser sollte min. 2 Features und ein gold label enthalten. <br/> Falls Ihnen kein Thema einfällt können sie eins der folgenden wählen:\n",
    "<ul>\n",
    "    <li> Lieblingsbücher (target: 1-5 Sternebewertung) </li>\n",
    "    <li> Fernsehserien (target: Genre) </li>\n",
    "    <li> Schmuck (target: Preis) </li>\n",
    "</ul>\n",
    "<br>    \n",
    "<i>Create a short dummy record (MyDataset.csv) with at least 20 instances on a topic of your choice. This should contain at least 2 features and a gold label. <br/> If you can't think of a topic, you can choose one of the following:</i>\n",
    "<br><br>\n",
    "<ul>\n",
    "    <li><i> Favourite books (target: 1-5 star rating) </i></li>\n",
    "    <li><i> TV series (target: genre) </i></li>\n",
    "    <li><i> Jewellery (target: price)</i></li>\n",
    "</ul>\n",
    "<br><br>\n",
    "2. Nutzen Sie die Daten im Machine Learning Prozess. <br> Dazu gehört: Daten aufsplitten, Classifier aussuchen (Begründen Sie Ihre Wahl), Test-Daten klassifizieren. <br> <br>*Use the data in the machine learning process. <br> This includes: splitting the data, selecting classifiers (justify your choice), classifying test data.* \n",
    "<br><br>\n",
    "3. Evaluieren Sie die Ergebnisse. Geben Sie dafür Beispiele zu mindestens 2 von Ihnen gewählten Evaluierungsmaßen und beschreiben Sie als wie gut Sie die Ergebnisse halten und was man evtl. verbessern könnte.<br><br>*Evaluate the results. Give examples of at least 2 evaluation measures you have chosen and describe how well you think the results are and what could be improved.* <br>\n",
    "\n",
    "__Hinweis!__ In der Abgabe müssen folgende Elemente enthalten sein:\n",
    "1. Datensatz\n",
    "2. Code\n",
    "3. Ein kurzer Bericht über die Vorgehensweise\n",
    "4. Ausgaben wie z.B. Evaluierungsmaße\n",
    "\n",
    "*__NOTE!__ The following elements must be included in the submission:*<br>\n",
    "1. *data set*\n",
    "2. *code*\n",
    "3. *a brief report on the approach taken*\n",
    "4. *outputs such as evaluation measures*\n",
    "\n",
    "\n",
    "Die Punkte 2 bis 4 sind zusammen in einem Jupyter Notebook abzugeben.<br>\n",
    "*The tasks 2 to 4 are to be handed in together in a Jupyter notebook.*"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
